<h1 align="center">Bangalore_House_Price_Estimation Project</h1>
<h2 align="left">Introduction :</h2>
Buying a house is a stressful thing. One has to pay huge sums of money and invest many hours and even there is a persisting concern whether it’s a good deal or not. Buyers are generally not aware of factors that influence the house prices. Almost all the houses are described by the total area in square foot, the neighbourhood and the number of bedrooms. Sometimes houses are even priced at X rupees per square foot. This creates an illusion that house prices are dependent almost solely on the above factors. Most of the houses are bought though real estate agents. People rarely buy directly from the seller, since there are a lot of legal terminology and paperwork’s involved and people are unaware of them. Hence real estate agents are trusted with the communication between buyers and sellers as well as laying down a legal contact for the transfer. This just creates a middle man and increase the cost of the house. Therefore the houses are overpriced and buyer should have a better idea of the actual value of the houses.
This project covers the measures that have been taken by the use of technology that is accessible and utilize them to create an unbiased system for predicting the house prices. The authors have utilized the previously gathered data from trusted resources and trained and designed a Machine Learning model in such a way that it provides the best possible predictions of house prices as an output to the user. Thus, this method in which the complete prediction is based upon the previously gathered data, the integrity and trustfulness of the system to the user is maintained.

<h2 align="left">Problem Statement :</h2>

Machine learning has been used for years to offer image recognition, spam detection, natural speech comprehension, product recommendations, and medical diagnoses. Today, machine learning algorithms can help us enhance cyber security, ensure public safety, and improve medical outcomes. Machine learning systems can also make customer service better and automobiles safer .When we started experimenting with machine learning, we wanted to come up with an application that would solve a real-world problem but would not be too complicated to implement. We also wanted to practice working with regression algorithms. So I started looking for a problem worth solving. Here’s what we came up with. If you’re going to sell a house, you need to know what price tag to put on it. And a computer algorithm can give you an accurate estimate! With the given features (categorical and continuous) build a model to predict the price of houses in Bengaluru.
<h2 align="left">Proposed Solution :</h2>
Nowadays, e-education and e-learning is highly influenced. Everything is shifting from manual to automated systems. The objective of this project is to predict the house prices so as to minimize the problems faced by the customer. The present method is that the customer approaches a real estate agent to manage his/her investments and suggest suitable estates for his investments. But this method is risky as the agent might predict wrong estates and thus leading to loss of the customer’s investments. The manual method which is currently used in the market is out dated and has high risk. So as to overcome this fault, there is a need for an updated and automated system. Data mining algorithms as well as Machine Learning algorithms can be used to help investors to invest in an appropriate estate according to their mentioned requirements. Also the new system will be cost and time efficient .This will have simple operations. In our project, the proposed system works on Linear Regression Algorithm. In today’s real estate world, it has become tough to store such huge data and extract them for one’s own requirement. Also, the extracted data should be useful. The system makes optimal use of the Linear Regression Algorithm. The system makes use of such data in the most efficient way.
In this paper, the linear regression algorithm helps to full fill customers by increasing the accuracy of estate choice and reducing the risk of investing in an estate. A lot of features that could be added to make the system more widely acceptable.
We have applied very efficient and logical feature extraction techniques so as to increase the accuracy. For example, we have done removal of outliers by using the business logic and bathroom feature. We know that if someone is going to buy a house of say 2000 sqft, then he should have at least 3 to 4 bedrooms. Any other cases in which there are only 2 rooms in 2000 sq ft, has been removed as an outlier. Another feature is the removal of cases where there are absurd numbers of bathrooms. By our logic, the total number of bathrooms should be at most 1 more than total number of bedrooms, i.e. total bath=total BHK+1. Therefore, we removed any other cases from the data frame where the cases were contradictory.
One of the major future scopes is adding estate database of more cities which will provide the user to explore more estates and reach an accurate decision.
<h2 align="left">Dataset :</h2>
There's a lot of data involved in fully training the model. The dataset is kept under a same directory. All pre-preprocessing scripts will, by default, output the clean data to a new directory created in the datasets root directory.
The following dataset has been used:
• This dataset was prepared as a record for the house prices of different houses at different locations in the city of Bengaluru by various government authorities. This dataset is a large collection of over 13321 records and 9 columns of house price data collected by various trusted sources. It consists of the following features: area_type, availability,loaction,size,society,total_sqft,bath,balcony,price. In these features, the price column is the labelled attribute.
<h2 align="left">Methodology :</h2>
 <h5>1. Pre-Processing and Data Cleaning :</h5>
Data preprocessing is an integral step in Machine Learning as the quality of data and the useful information that can be derived from it directly affects the ability of our model to learn; therefore, it is extremely important that we preprocess our data before feeding it into our model.Data cleaning is the process of fixing or removing incorrect, corrupted, incorrectly formatted, duplicate, or incomplete data within a dataset. When combining multiple data sources, there are many opportunities for data to be duplicated or mislabeled.
 <h5>2. Feature Engineering :</h5>
Feature engineering is the process of using domain knowledge of the data to create features that make machine learning algorithms work. If feature engineering is done correctly, it increases the predictive power of machine learning algorithms by creating features from raw data that help facilitate the machine learning process. Feature Engineering is an art .In our project, it includes exploring the total_sqft feature and also adds new feature price per square feet.

 <h5>3. Dimensionality Reduction and Outlier Removal :</h5>
Dimensionality reduction refers to techniques for reducing the number of input variables in training data. Fewer input dimensions often mean correspondingly fewer parameters or a simpler structure in the machine learning model, referred to as degrees of freedom. In our project, any location which had number of houses less than 10 has been marked as “others” so as to reduce the dimensions of the dataset.
Outliers badly affect mean and standard deviation of the dataset. These may statistically give erroneous results.
It increases the error variance and reduces the power of statistical tests. If the outliers are non-randomly distributed, they can decrease normality. So we applied various logics such as business logic, bathroom feature to remove the outliers.
 <h5>4. Model Building and Accuracy :</h5>
In our project, the model was implemented using the Linear Regression Algorithm. All the necessary libraries were imported and training of the model was done. We saw that in 5 iterations we get a score above 85% all the time. This was a very good accuracy score and we continued to use the algorithm. Also we compared different algoritms, such as Lasso Regression, Decision Tree and Linear Regression using the GridSearchCV technique to find the model with best accuracy, which we found that it is Linear Regression.

<h2 align="left">Conclusion :</h2>
The framework makes ideal utilization of the Linear Regression Algorithm. It makes use of such information in the most effective way. The direct relapse calculation satisfying customer by expanding the exactness of their decision and diminishing the danger of putting resources into a home. One of the real future extensions is including home database of more urban areas which will give the client to investigate more domains and achieve an exact choice. More factors like subsidence that influence the house costs should be included. Top to bottom subtle elements of each property will be added to give plentiful points of interest of a coveted domain. The authors were able to create a system with more than 85% accuracy and the utilization of dataset was done with great efficiency which ultimately gave quite impressive results.
